Type hints introduced syntax and semantics for explicit declarations in function arguments, return values and variables.
	GOAL --> help developer tools find bugs in Python codebases via static analysis i.e., without actually running the code through tests.

Main beneficiaries
	SEs using IDEs
	Continous Intergration

Given the limitations of static type system, we introduce Gradual type system.

GRADUAL TYPING
	Other languages with Gradual type system are
		Microsoft's TypeScript
		Dart -- of Flutter SDK
		Hack

A Gradual type system:
	Is optional:
		Should not emit warnings for code that has no type hints.
		It assumes the 'Any' type when it cannot determine the type of an object
	Does not catch type errors at runtime
		They do not prevent inconsistent values from being passed to functions or assigned to variables at runtime.
	Does not enhance performance
		In theory, it provides data that could be used to optimize the generated bytecode, but such optimizations are not implemented in any Python runtime.

Available python type checkers
	Googles's pytype
	Microsoft's Pyright
	Facebook's Pyre
	Mypy

A just-in-time compiler like the one in PyPy has much better data than type hints: it monitors the Python program as it runs, detects the concete types in use, and generates optimized machine code for those concrete types.

mypy messages_test.py --> is not working
	CHECK WHEN FREE

MYPY commands
	mypy filename.py
	mypy --disallow-untyped-defs filename.py
	mypy --disallow-incomplete-defs filename.py

	Instead of writing these ugly commands, we can change settings by running a file(see MyPy documentation for more details)
		filename:- mypy.ini
		file contents:- 
			[mypy]
			python_version = 3.9
			warn_unused_configs = True
			disallow_incomplete_defs = True

Use tools like:-
	flake8
	blue
to do code styling and it helps rewrite source cofde according to rules embedded in the 'black' code formatting tool.

Single quotted representation of strings is preferred.
	The 'doctest' module depends on repr() using single quotes by default

In many contexts, 'None' is a better default.
	If the optional parameters expects a mutable type, then 'None' is the only sensible default.

	To use 'None' as default for string type, use it like this:
		from typing import Optional
		def show_count(count: int, singular: str, plural: Optional[str] = None) -> str:

	Optional[str] --> means plural may be a 'str' or 'None'

	Optional is not a great name because it is not optional until we give the default value for the same

TYPES ARE DEFINED BY SUPPORTED OPERATIONS
	abc.Sequence --> does not have __mul__ hence the * operator will give error in MyPy

	In gradual type system, we have the interplay of two different views of types:-
		1. DUCK TYPING

			Python
			JavaScript
			Ruby
			--> Informal form of 'structural typing'
			--> Objects have types, but variables(including parameters) are untyped
			--> duck typing is only enforced at runtime, when operations on objects are attempted.
			--> This is more flexible than 'Nominal typing'--> at the cost of allowing more errors at runtime.
		2. NOMINAL TYPING
			C++
			Java
			C#
			Objects and variables have types.
			But objects only exist during runtime.
			and the type checker only cares about the source code where variables are annoted by type hints.
			This is more rigid than 'duck typing', with the advantage of catching some bugs earlier in a build pipeline, or even as the code is typed in an IDE.

	At runtime, python uses --> 'duck typing'
	Downside of 'duck typing' --> it allows unsupported operations to cause errors at runtime. But Nominal typing detects errors before runtime, but sometimes rejects code that actually runs.

The benefits of using type-hints grow with the size of the codebase.
	Thats why companies like Google, Dropbox, Facebook use these
		their Python codebases are type-checked in their CI pipelines.

TYPES USABLE IN ANNOTATIONS
	typing.Any
	Simple types and classes
	typing.Optional and typing.Union
	Generic collections, including tuples and mappings
	Abstract base classes
	Generic iterables
	Parameterized generics and TypeVar
	typing.Protocols -- the key to 'static duck typing'
	typing.Callable
	typing.NoReturn

We will cover each one of these

TYPING.ANY
	The keystone of any gradual type system is 'Any' type, 
		also known as 'Dynamic type'.

	The type checker assumes 'Any' for an untyped function

	In contrast:
	def double(x: object) -> object:
		This function also accepts arguments of every type, because every type is a subtype-of 'object' (CLASS?).

		However the type checker will reject this function because 'object' does not implement * operator.

	The 'object' class implements fewer operations than abc.Sequence which implements fewer operations than abc.MutableSequences which implement fewer operations than 'list'.

	'Any' prevents the type checker from fulfilling its core mission: detecting potentially illegal operations before your program crashes with a runtime expection.


	SUBTYPE-OF vs CONSISTENT-WITH
		Definition of 'subtype-of' a.k.a. 'behaviourial subtyping'
			If an object of type T2 substitutes an object of type T1 and the program still behaves correctly, then T2 is a 'subtype-of' T1.
			This is called "Liskov Substitution Principle{LSP}"
				 Liskov Substitution Principle (LSP) states that objects of a superclass should be replaceable with objects of its subclasses without breaking the application
			--> As a subclass, T2 inherits and must support all operations that T1 does. So an instance of T2 can be used anywhere an instance of T1 is expected

			class T1:
				...

			class T2(T1):
				...

			def f1(p: T1) -> None:
				...

			o2 = T2()
			f1(o2)       ---------------> this is "OK"


			def f2(p: T2) -> None:      $$$ T2 may contain extra functions. The function expects a T2 hence calls the additional functions implemented in T2, but not in T1, hence if we pass a T1 object we cannot access those methods and it is ERROR. GGEZ
				...
			o1 = T1()
			f2(o1)       ---------------> this is "TYPE ERROR" according LSP

		In gradual type system, there is another relationship: "consistent-with", which applies wherever "subtype-of" applies, with special provisions for type 'Any'.

		The rules for 'consistent-with' are:-
			1. Given T1 and a subtype T2, then T2 is consistent-with T1.
			2. Every type is "consistent-with" 'Any'
			3. 'Any' is "consistent-with" every type --> we can pass an argument of type 'Any' where argument of another type is predefined.

	Every gradual type system needs a wildcard type like 'Any'.


SIMPLE TYPES AND CLASSES
	Among classes, 'consistent-with' is defined like 'subtype-of':- a subclass is 'consistent-with' all its superclasses.

	'int' is consistent with 'complex'

	int, float, complex --> are direct subclasses of 'object'
	But PEP484 --> declares that 'int' is consistent-with float
							 and 'float' is consistent-with complex


TYPING.OPTIONAL AND TYPING.UNION TYPES
	Optional[str] is a shortcut for Union[str, None] --> which means the type of plural may be 'str' or 'None'

	Better syntax --> we can write --> str | bytes instead of Union(str, bytes)
		+ no need to import typing
		EXAMPLE	
		plural: Optional[str] = None   $$$ Old way
		plural: str | None = None

	The '|' operator works with 'isinstance' and  'issubclass' to build the second argument
		FOR EXAMPLE	:-
			isinstance(x, int | str)

	If possible, avoid creating functions that return Union types, as they put an extra burden on the user -- forcing them to check the return type of returned value at runtime

	The 'ord' built-in function's signature --> it accepts 'str' or 'bytes' and returns an 'int'
		def ord(c: Union[str, bytes]) -> int:
				To be more precise, ord only accepts str or bytes with len(s)==1. But the type system currently can't express this constraint.

	If a function returns according to the input parameter type, then we cannot use Union. For example:-
			If a function takes str and gives str 
					  AND takes bytes and gives bytes, we cannot use UNION because the return type is certain.
		To properly annotate such functions, we need a type variable -- presented in "Parameterized Generics and TypeVar" -- or overloading which we'll see in "Overloading Signatures".

	Union[] --> requires atleast two types.

	Nested Union has the same effect as flattened Union.

	Union is more powerful with types that are not consistent among themselves. For example:-
			Union[int, float] is redundant because int is consistent-with float


GENERIC COLLECTIONS
	Generic types can be declared with type parameters to specify the type of the items they can handle.
		For example:- list[str]
		Hence the annotations--> stuff: list and stuff: list[Any] mean the same thing.

	The following list shows only those collections that use the simplest form of generic type hint--> of format: container[item] :-
		list
		set
		frozenset
		collections.deque
		abc.Container
		abc.Collection
		abc.Sequence
		abc.Set
		abc.MutableSequence
		abc.MutableSet

	'tuple' and mapping types support more complex type hints, as we will see later.

	As of Python 3.10, there is no good way of annotating array.array.
		We cant decide the 'typecode' argument which determines whether integers or floats are stored in the array.
		A even harder problem is to check OverflowError at runtime

TUPLE TYPES
	Three ways to annotate tuples:-
		1. Tuples as records
		2. Tuples as records with named fields
		3. Tuples as immutable sequences

	TUPLES AS REORDS
		For example:- tuple[str, float, int]

	TUPLES AS RECORDS WITH NAMED FIELDS
		use 'typing.NamedTuple'
			NamedTuple is a factory for 'tuple' subclasses
		see JPN for examples

	TUPLES AS IMMUTABLE SEQUENCES
		To annotate tuples of unspecified length that are used as immutable lists --> specify a single type, followed by comma and three dots ...   {those ... are called Python's ellipsis token --> made of three periods not Unicode U+2026 -- HORIZONTAL ELLIPSIS}

		For example: - tuple[int, ...] --> tuple of 'int' items

		The annotations stuff: tuple[Any, ...] and stuff: tuple --> mean the same thing

GENERIC MAPPINGS
	Generic mapping types are annotated by 'MappingType[KeyType, ValueType]'
		'dict'
		the mapping types in collections and collections.abc

		Given starting and end index of Unicode character codes, name_index returns a dict[str, set[str]], which is an inverted index mapping each word to a set of characters that have that word in their names.
		see JPN for examples.


"Be conservative in what you send, be liberal in what you accept" --> Postel's law, a.k.a. the Robustness Principle.

ABSTRACT BASE CLASSES
	Ideally, a function should accept arguments of type {abstract classes from collections.abc} -- or their typing equivalents -- and not concrete types.
		This gives more flexibility to the caller.

	Using collections.abc.Mapping allows the user to provide an instance of 'dict', 'defaultdict', 'ChainMap', 'UserDict' subclass or any other type that is "subtype-of" Mapping

	Actually, dict is a virtual subclass of abc.MutableMapping

	Under typing.List 's documentations:-
		Useful for annotating return types. To annotate arguments it is preferred to use an abstract collection type suchc as Sequence or Iterable

	The 'numbers' package defines the so-called 'numeric tower' -- A Type Hierarchy for Numbers
		Number
		Complex
		Real
		Rational
		Integral

	If you want to annotate numeric arguments for static type checking :-
		1. use one of the concrete types  --> int, float, comple
		2. Declare a union type --> Union[float, Decimal, Fraction]
		3. If you wan to avoid hardcoding concrete types, use numeric protocols like SupportsFloat
				--> this topic is covered later in this book

As of Python 3.10 there are no type hints in standard libraries but MyPy and Pycharm can find the necessary type hints in the "Typeshed" project, in the form of stub files: a special source fileswith .pyi extension that have annotated function and method signatures, without implementation -- much like header files in C.


ITERABLE
	Most useful ABC
	Example:- Iterable[float]

	abc.Iterable vs abc.Sequence
		iterable.cycle --> is an endless iterable 
		Despite potential danger, it is common in Modern python to offer functions that accept an Iterable input even if they must process it completely to return a result.
			This gives the option of providing input data as generator instead of a prebuilt sequence, potentially saving lots of memory

PARAMETERIZED GENERICS AND TypeVar
	A parameterized generic is a generic type written as list[T] where T is a type variable that will be bound to a specific type with each usage. This allows a parameter to be reflected on the result type

	Sequence[T] --> is a clever implementation of metaprogramming

	There is no generics in Python as compared to other languages which have. {I mean Python can't understand if we just put T, but other languages can understand. This is the reason of introducing typing.TypeVar}

	import statistics

	It is wrong to do this :-
		T = TypeVar('T')
		def mode(data: Iterator[T]) -> T:       👎👎👎👎 WRONG 👎👎👎👎

	"Every" iterable is 'consistent-with' Iterable[T]
		We'll see two ways of correcting the above mistake :-
			1. RESTRICTED TYPEVAR
				TypeVar accepts extra positional arguments to restrict the type parameter. For example:-	
					NumberT = TypeVar('NumberT', float, Decimal, Fraction)
					def mode(data: Iterator[NumberT]) -> NumberT:

			2. BOUNDED TYPEVAR
				It sets an upper boundary for the acceptable types.
				For example:- bound = Hashable

		A restricted typeVar will be set to one of the names defined while defining it.
		A bounded typeVar variable will be set to the inferred type of the expression -- as long as inferred one is 'consistent-with' the boundary declared while defining it.

	The typing.TypeVar has other optional parameters -- 'covariant' and 'contravariant' -- will be covered later.

	The typing module includes a predefined TypeVar named 'AnyStr' defined like this :-
		AnyStr = Typevar('AnyStr', bytes, str)

STATIC PROTOCOLS
	typing.Protocol
	Protocol <--> informal interface

	A protocol --> is a typing.Protocol subclass defining an interface that a type checker can verify.

	However, classes that implement a protocol don't need to inherit, register or declare any relationship with the class that defines the protocol.	
		It is upto the ckecker to find the avialable protocol types and enforce their usage.

	To be able to sort an Iterable, we need to have that --> the values must support __lt__

	from typing import Protocol, Any

	class SupportsLesssThan(Protocol):
		def __lt__(self, other: Any) -> bool:

	T is 'consistent-with' with a protocol P if T implements all the methods defined in P, with matching type signatures.

	A key advantage of protocol type over ABCs is that a type doesnt need any special declaration to be 'consistent-with' a protocol type

	This feature is known as static duck typing.
		typing.Protocol --> gives us static duck typing.

	typing.Protocol makes it possible to annotate this function
		def double(x: abc.Sequence):
			return x *2
	without losing its functionality. The key is to define a Protocol subclass with __mul__ method


CALLABLE
	To annotate callback parameters or callable object returned by higher-order functions, 
		the collections.abc module provides the 'Callable' type (also available in tying module)

	A 'Callable' type is parameterized like this:
		Callable[[ParamType1, ParamType2], ReturnType]

	For example:-
		def repl(inpit_fn: Callable[[Any], str] = input) -> None:
		--> here Any is ParamType1
				 str is the ReturnType

	To match a function with a flexible signature use this:-
		Callable[..., ReturnType]

	The intepretation of generic type parameters with a type hierarchy introduces a new typing concept --> VARIANCE.

	Callable[[], int] is "subtype-of" Callable[[], float]
		Callable is "covariant" on the return type because of the "subtype-of" relationship of the types 'int' and 'float' is in the same direction as that of the Callable types that use them as return types.

	Callable[[int], None] is NOT "subtype-of" Callable[[float], None]
		--> here it is called "contravariant"

NoReturn
	Usually, they raise expections
	Examples of such functions are:-	
		sys.exit() --> raises 'SystemExit' to terminate the Python process.

	Its signature in 'typeshed' is:-
		def exit(_status: object = ...) -> NoReturn: ...

	Stub files dont spell out default values, instead they use ...

ANNOTATING  POSITIONAL ONLY AND VARIADIC PARAMETERS
	def tag(
		name: str,
		/,
		*content = str,
		class_ = Optional[str] = None,
		**attrs = str,
	) -> str:

	The type of "content" --> tuple[str, ...]

	The type hint for the arbitrary keyword argumentsis **attrs: str
		Therefore it is of type --> dict[str, str]

	If it was --> **attrs: float
		Then it is of type --> dict[str, float]

	If the attrs parameter must accept values of different types, use
		Union[] or Any: **atrs: Any

IMPERFECT TYPING AND STRONG TESTING
	Bugs are fixed more cheaply by using static type checkers.

	In static type checkers, its not hard to find:-	
		1. False positives
		2. False negatives

	Some features cannot be type checked.
	Advanced features like:- 
		properties
		descriptors
		metaclasses
		metaprogramming
	are poorly supported or beyond comprehension by type checkers

	Common data constraints cannot be expressed in type system. --> even simple ones

	The point of a CI pipeline is to reduce software failures and automated tests catch many bugs that are beyond reach of type hints

Protocol enables static duck typing --> the essential bridge between Python's duck-typed core and the nominal typing that allows static type checkers to catch bugs.

