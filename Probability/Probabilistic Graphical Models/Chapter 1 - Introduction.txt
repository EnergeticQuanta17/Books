*1.2 Structured Probabilistic Models*
General purpose framework for constructing and using probabilistic models of complex systems

Complex systems are characterized by the presence of multiple interrelated aspects many of which relate to the reasoning task.

In order to do so using principled probabilisitc reasoning, we need to construct a joint distribution over the space of all possible assignments.\
This type of model allows us to answer a broad range of interesting queries.


1.2.1 Probabilistic Graphical Models
This book describes the framework of probabilistic graphical models which provides a mechanism for exploiting the structure in complex distributions to describe them compactly, and in a way that allows them to constructed and utilized effectively.

PGMs use a graph-based representation as the basis for compactly encoding a complex distribution over a high-dimensional space.

	Bayesian networks and Markov networks, also known as Markov random fields, are both types of graphical models used to represent and reason about probabilistic relationships among variables. However, there are some key differences between the two models:

	Directed vs. Undirected: Bayesian networks are directed acyclic graphs (DAGs) that represent a set of variables and their conditional dependencies using arrows. Markov networks, on the other hand, are undirected graphs that represent the joint probability distribution of a set of variables using a graph without arrows.

	Causality vs. Association: Bayesian networks represent the causal relationships among variables, whereas Markov networks represent the association between variables. In a Bayesian network, the arrows indicate the causal direction of the relationship between the variables, while in a Markov network, the edges indicate the degree of similarity or interaction between the variables.

	Conditional Probability vs. Energy Function: Bayesian networks use conditional probability distributions to specify the relationships among variables, while Markov networks use an energy function that assigns a score to each configuration of the variables.

	Independence assumptions: Bayesian networks represent conditional independence relationships among variables using the concept of d-separation, while Markov networks represent the independence relationships using the concept of pairwise Markov properties.

PGM - (Idk about Markov one) These networks have a kind of Markovian property  -> they only depend on the immediate connections.
The previous information become no longer informative.
This assertion just means that information that we may obtain from X, we have already obtained by knowing the immediate dependency.

The other prespective - graph defines a skeleton for compactly representing a high dimensional distribution, rather than encode the probability of every possible assignment to all of the variables in our domain, we can break up the distribution into smaller factors each over a smaller space of possibilities.
We can then define the overall joint distribution as a product of these factors

Page 5 - Did not understand the example of 3+4+4+4+2 = 17 nonredundant parameters

It turns out that these two perspectives -- 
	the graph as a representation of a set of independencies 
	and 
	the graph as a skeleton for factorizing a distribution -- are in a deep sense --> EQUIVALENT.

	The independece properties of the distribution are precisely what allow it to be represented compactly in a factorized form.

	Conversely, a particular factorization of the distribution garuntees that certain independencies hold.

Two families of graphical representations of distributions
	Bayesian Networks
		Directed Graph - where there is source and target

	Markov Networks
		Undirected graph
		It can too be viewed as defining a set of independence assertions or as encoding a compact factorization of the distribution .

Both representations provide the duality of independencies and factorization,
	but they differ in the set of independencies they can encode and in the factorization of the distribution that they induce.

1.2.2 Representation, Inference, Learning
	Property used in graphical learning --> The property that variables tends to interact directly only with very few others.
	
	This framework has many advantages.
	1. Allows the distribution to be written down tractably.
	2. The type of representation provided by this framework is transparent - This property is important for constructing models that provide an accurate reflection of our understanding of a domain. Models that are opaque can easily give rise to unexplained, and even undesirable, answers.
	3. The same structure often also allows the distribution to be used effectively for inference - answering queries using the distribution as our model of the world. 
		We provide algorithms for computing the posterior probability of some variables given evidence on others. 
		These inferences work directly on the graph structure and generally orders of magnitude faster than manipulating the joint distribution explicitly.
	4. This framework facilitates the effective construction of these models.
	These methods support "Data-Driven Approach" to model construction that is very effective in practice. 
	In this approach, a human expert provides rough guidance on how to model given a domain --> like the number of attributes, often some of the main dependencies.
	I want metrics to test for the significance of creating a bond between two variables (bond meaning directed arrow from one to another node)
	The details are usually filled in automatically,  by fitting the model to the data. 
	The models produced by this process are usually much better refletions of the domain than models that are purely hand-constructed.
	Moreover, they can sometimes reveal surprising connections between variables and provide novel insights about the domain.

These three components - representation, inference, and learning - are critical components in constructing an intelligent system. We need a declarative representation that is a reasonable encoding of our world model. We need to be able to use this representation effectively to answer a broad range of questions that are of interest. And we need to be able to aquire this distribution, combining expert knowledge and accumulated data. PGMs are one of a small handful of frameworks that support all three capabilities for a broad range of problems.

I want interest specific models. Usually the model is constructed then the question is asked.
say I have already formed the question, construct the model that gives the best possible answer given my question.


OVERVIEW OF THE CHAPTERS

Chapter 2 - basic model
	using graphs to encode distributions
	properties of such distributions

Chapter 3 - describe the Bayesian Network representation based on directed graphs
	Bayesian network to encode probability distribution
	Independence properties induced by the graph structure

Chapter 4 - Markov Networks
	independencies defined by the graph
	induced factorization of the distribution
	relationship between Markov networks and Bayesian Networks
	Briefly describes a framework that unifies both

Chapter 5 - 

OMG THERE ARE 23 CHAPTERS, I'll write this later

1.3.2 Reader's Guide
This book relate to multiple fields and techniques from other disciplines
	Probability Theory
	Computer Science
	Information Theory
	Optimization
	Statistics and more

1.3.3 Connection to Other Disciplines
From Computer Science, We look at graph as a data structure.
From  Algorithmic Ideas, the ability to manipulate probability distributions using discrete data structures and key elements that make the probabilisitc manipulations tractable.
Decision Theory extends these basic ideas to the task of decision making under uncertianty.

These models inherit the idea of using a declarative representation of the world to separate procedural reasoning from our domain knowledge.

Statistics plays a role in representation and learning models from data.

Optimization plays a role in providing algorithms for approximate inference and for learning models from the data.

Bayesian Network - arose in the setting of modeling genetic inheritance in human family trees.

Information Theory plays a dual role in this.	
	Entropy and Information 
	Coding theory based on the relationship between inference in probabilistic models and the task of decoding messages sent over a noisy network --> error correcting codes and practice of approximate message-passing algorithms in graphical models.


1.3.3.1 What have we gained?
	The use of structure to allow compact representation, effective reasoning, and feasible learning of general-purpose, factored, probabilistic models. These elements provide us with a general infrastructure for reasoning and learning about complex domains.

By using declarative representation, we essentially separate out the description of the model for the particular application, and the general purpose algorithms used in inference and learning. Thus, this framework provides a general algorithmic toolkit that can be applied to many different domains.

These models provide a formal framework for a variety of fundamental problems
	1. Notion of conditional independence and its explicit graph based representation - sensor variables - Bayesian conditioning
	2. Proviees formal measure for the model quality 
	This measure underlies much of our work on learning models from data.
	The temporal models we define provide a formal framework for defining a general trend toward persistence of state over time, in a way that does not raise inconsistencies when change does occur.

Algorithms for which no theoretical analysis exists are tried out in practice, and the profile of where they succeed and fail often provides the basis for subsequent analysis.

DID NOT READ HISTORICAL NOTES